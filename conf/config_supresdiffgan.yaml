mode: 'train-test'
use_perceptual_loss: true

model:
  name: 'SupResDiffGAN'
  lr: 0.00005 
  alfa_perceptual: 0.01 
  alfa_adv: 0.01 
  load_model: null

trainer:
  max_epochs: 250
  max_steps: -1
  check_val_every_n_epoch: 5
  limit_val_batches: 0.25
  log_every_n_steps: 10
  precision: '16-mixed' # Keep mixed precision for memory
  accelerator: 'gpu'
  devices: 1
  accumulate_grad_batches: 2 # Can reduce this slightly, e.g., to 2 (effective batch 8)
  resume_from_checkpoint: null

dataset:
  name: 'celeb'
  batch_size: 4 # Keep small batch size
  resize: true
  scale: 4

evaluation:
  mode: 'all'
  steps: [50, 100, 200]
  posteriors: ['ddpm', 'ddim']
  save_results: true
  results_file: 'evaluation_results/final_evaluation.csv' # New file

checkpoint:
  monitor: 'val/LPIPS'
  dirpath: 'models/checkpoints_medium/' # New directory
  save_top_k: 1
  mode: 'min'
  save_last: true
  filename: 'SupResDiffGAN-{epoch:02d}-{val/LPIPS:.4f}' # New name

autoencoder: 'VAE' # This now refers to AutoencoderKL
feature_extractor: true

unet:
  - 64
  - 96
  - 128
  - 256 # <-- REDUCED from 512 (faster)

diffusion:
  timesteps: 200
  beta_type: 'cosine'
  posterior_type: 'ddpm'
  validation_timesteps: 100
  validation_posterior_type: 'ddim'

discriminator:
  in_channels: 6
  channels:
    - 64
    - 128
    - 256 # <-- REDUCED from 512 (faster)

wandb:
  project: 'SupResDiffGAN'
  entity: 'samarthya04-kiit-deemed-to-be-university'